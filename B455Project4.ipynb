{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKMmLzaBfa-y"
   },
   "source": [
    "# B455 Project 4\n",
    "**By Owen Gordon**<br><br>\n",
    "\n",
    "For this project I am going to perform sentiment analysis on movie reviews from IMDb. Each review is given a rating of 1 to 10 stars. My models will try to predict the overall sentiment - positive if 6 stars or greater, and negative if 5 stars or fewer - and also try to predict the actual number of stars. <br><br>\n",
    "\n",
    "The first step in performing the analysis is to load the training and testing data. There are 50,000 total samples, 25,000 training samples and 25,000 testing samples. Within each group of training and testing samples, there are 12,500 positive reviews and 12,500 negative reviews. <br><br>\n",
    "\n",
    "I used the .open function in python to load the files, and then I split each line into a vector containing both the label (number of stars) and the words in the review. The file is in LIBSVM format which means that the data is stored {\"word\" : \"frequency\"}. The \"word\" is a number corresponding to the word index in the imbd.vocab file, and the \"frequency\" is the number of times that word appears in the review. <br><br>\n",
    "\n",
    "Note: The original files containing the training and testing data are both titled \"labeledBow.feat\", so I had to change the names to be able to contain both in the root directory. My file containing the training data is titled \"train_labeledBow.feat\" and my file containing the testing data is titled \"test_labeledBow.feat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "owuFdwasnQcL"
   },
   "outputs": [],
   "source": [
    "# read in the files\n",
    "train = open('train_labeledBow.feat', 'r')\n",
    "test = open('test_labeledBow.feat', 'r')\n",
    "\n",
    "# read the lines in the file and split at each space to seperate the words\n",
    "train_features = [line.split(' ') for line in train.readlines()]\n",
    "test_features = [line.split(' ') for line in test.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrmSQ31Ai67Q"
   },
   "source": [
    "The final part in the preprocessing is to take the vector for each review, and extract the numerical values. Since the \"word\" is split from the \"frequency\" with a colon, I split each string into an array with two values, the first being the word number, and the second being the word frequency in the review. Then to aid in searching later on, I turned this array into a dictionary with all the keys being the word numbers, and the corresponding values being the frequency. This dictionary, along with the review target was placed into another dictionary with two keys. The first key is \"output\" and contains the integer value of the number of stars the review gave, and the second key is \"input\" which contains the dictionary of word - frequency pairs. The last step is to put each of these dictionaries into a large array that contains all of the training data and one that contains all of the testing data. <br><br>\n",
    "\n",
    "The data should now be fully preprocessed and ready to be used in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "40OyW5gBGK9h"
   },
   "outputs": [],
   "source": [
    "# arrays that will contain all of the data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# loop over all of the training features and testing features\n",
    "for train_feature, test_feature in zip(train_features, test_features):\n",
    "  # split word-frequency for the inputs\n",
    "  train_inputs = [f.split(':') for f in train_feature[1:]] \n",
    "  test_inputs = [f.split(':') for f in test_feature[1:]]\n",
    "  train_input_dict = {}\n",
    "  test_input_dict = {}\n",
    "\n",
    "  # create key-value pairs in the input dictionary\n",
    "  for train in train_inputs:\n",
    "      train_input_dict[int(train[0].strip('\\n'))] = int(train[1].strip('\\n'))\n",
    "  for test in test_inputs:\n",
    "    test_input_dict[int(test[0].strip('\\n'))] = int(test[1].strip('\\n'))\n",
    "\n",
    "  # put output and intput data into dictionary\n",
    "  train_d = {'output': int(train_feature[0]), 'input': train_input_dict}\n",
    "  test_d = {'output': int(test_feature[0]), 'input': test_input_dict}\n",
    "\n",
    "  # add dictionaries to arrays that contain all the data\n",
    "  train_data.append(train_d)\n",
    "  test_data.append(test_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bno0Zva5n8eZ"
   },
   "source": [
    "For any of the inputs to make sense, I need assign word polarity. For that, I am going to use the word polarities given in the \"imdbEr.txt\" file. This file contains a value for every word in the review dictionaries. I applied the same technique to read this data in as I used to read in the other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k8wngVL5BWb9"
   },
   "outputs": [],
   "source": [
    "# open the file\n",
    "imdbEr = open('imdbEr.txt', 'r')\n",
    "\n",
    "# read the float value in each line\n",
    "vocab_values = [float(v.strip('\\n')) for v in imdbEr.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWbGSLp1m6KX"
   },
   "source": [
    "The first models I am going to train will try to predict the exact number of stars as outputs. I am going to use sklearn for the model types. The sklearn models that I am going to use are LogisticRegression, MLPClassifier, and MLPRegressor. I am going to reduce each input down into a single value which corresponsds to the sum of all word polarities in the review. This will use just the word occurence, not frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XNayLBsRpcJk"
   },
   "outputs": [],
   "source": [
    "# calculuate polarity values for each review \n",
    "X_train_occurrence = []\n",
    "X_test_occurrence = []\n",
    "\n",
    "for train, test in zip(train_data, test_data):\n",
    "  train_sum = 0\n",
    "  test_sum = 0\n",
    "  for word in train['input'].keys():\n",
    "    train_sum += vocab_values[word]\n",
    "  X_train_occurrence.append(train_sum)\n",
    "  for word in test['input'].keys():\n",
    "    test_sum += vocab_values[word]\n",
    "  X_test_occurrence.append(test_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rkyaC_Ulw2tT"
   },
   "outputs": [],
   "source": [
    "# collect targets into single array\n",
    "y_train_multi = [train['output'] for train in train_data]\n",
    "y_test_multi = [test['output'] for test in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ulzNezmAxPy-"
   },
   "outputs": [],
   "source": [
    "# reshape input arrays\n",
    "import numpy as np\n",
    "X_train_occurrence_np = np.array(X_train_occurrence).reshape(-1, 1)\n",
    "X_test_occurrence_np = np.array(X_test_occurrence).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOOLPhrtpXjn",
    "outputId": "a2ab1eca-d245-4010-8751-7fbe462952ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of multi class prediction using word occurrence\n",
      "Logistic Regression accuracy: 0.36648\n",
      "MLP Classifier accuracy: 0.36312\n",
      "MLP Regressor accuracy: 0.5715366909038879\n"
     ]
    }
   ],
   "source": [
    "# create the models and test accuracy using occurence\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "logistic_multi_occurrence = LogisticRegression()\n",
    "logistic_multi_occurrence.fit(X_train_occurrence_np, y_train_multi)\n",
    "logistic_multi_occurrence_accuracy = logistic_multi_occurrence.score(X_test_occurrence_np, y_test_multi)\n",
    "\n",
    "mlp_multi_occurrence = MLPClassifier()\n",
    "mlp_multi_occurrence.fit(X_train_occurrence_np, y_train_multi)\n",
    "mlp_multi_occurrence_accuracy = mlp_multi_occurrence.score(X_test_occurrence_np, y_test_multi)\n",
    "\n",
    "mlpr_multi_occurrence = MLPRegressor()\n",
    "mlpr_multi_occurrence.fit(X_train_occurrence_np, y_train_multi)\n",
    "mlpr_multi_occurrence_accuracy = mlpr_multi_occurrence.score(X_test_occurrence_np, y_test_multi)\n",
    "\n",
    "print(\"Accuracy of multi class prediction using word occurrence\")\n",
    "print(f\"Logistic Regression accuracy: {logistic_multi_occurrence_accuracy}\")\n",
    "print(f\"MLP Classifier accuracy: {mlp_multi_occurrence_accuracy}\")\n",
    "print(f\"MLP Regressor accuracy: {mlpr_multi_occurrence_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32Ev1Yh80L1m"
   },
   "source": [
    "Using multi class output, and word occurrence, it is clear that the MLP Regressor has the best prediction. 57% accurency is not phenomenal, but considering that there were 10 possible classes, and it was correct over half the time, this is not a terrible model. The other two models were very similar in their results. Both had a ~1/3 success rate. Given that a random guess would lead to 10% accurary, anything over 10% is learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HYZdbSw1RoY"
   },
   "source": [
    "The next models I am going to try is the multi class prediction using word frequency as well. I am going to reduce the inputs again, and this time multipy the polarity value by the frequency of that word in the review. Given that word occurence is usually more important than the frequency in the text, I anticipate that this will not dramatically improve the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCze7kP42Mph"
   },
   "outputs": [],
   "source": [
    "# calculuate polarity values for each review - this time incorporating word frequency\n",
    "X_train_frequency = []\n",
    "X_test_frequency = []\n",
    "\n",
    "for train, test in zip(train_data, test_data):\n",
    "  train_sum = 0\n",
    "  test_sum = 0\n",
    "  for word in train['input'].keys():\n",
    "    train_sum += (vocab_values[word] * train['input'][word])\n",
    "  X_train_frequency.append(train_sum)\n",
    "  for word in test['input'].keys():\n",
    "    test_sum += (vocab_values[word] * test['input'][word])\n",
    "  X_test_frequency.append(test_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FmStAkv52ykc"
   },
   "outputs": [],
   "source": [
    "# reshape input arrays again\n",
    "X_train_frequency_np = np.array(X_train_frequency).reshape(-1, 1)\n",
    "X_test_frequency_np = np.array(X_test_frequency).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vnhQ1ff25qG",
    "outputId": "7fa7ca19-8f27-4847-d4e6-c202106a35fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of multi class prediction using word frequency\n",
      "Logistic Regression accuracy: 0.35984\n",
      "MLP Classifier accuracy: 0.35656\n",
      "MLP Regressor accuracy: 0.534893570602633\n"
     ]
    }
   ],
   "source": [
    "# create the models and test accuracy using frequency\n",
    "logistic_multi_frequency = LogisticRegression()\n",
    "logistic_multi_frequency.fit(X_train_frequency_np, y_train_multi)\n",
    "logistic_multi_frequency_accuracy = logistic_multi_frequency.score(X_test_frequency_np, y_test_multi)\n",
    "\n",
    "mlp_multi_frequency = MLPClassifier()\n",
    "mlp_multi_frequency.fit(X_train_frequency_np, y_train_multi)\n",
    "mlp_multi_frequency_accuracy = mlp_multi_frequency.score(X_test_frequency_np, y_test_multi)\n",
    "\n",
    "mlpr_multi_frequency = MLPRegressor()\n",
    "mlpr_multi_frequency.fit(X_train_frequency_np, y_train_multi)\n",
    "mlpr_multi_frequency_accuracy = mlpr_multi_frequency.score(X_test_frequency_np, y_test_multi)\n",
    "\n",
    "print(\"Accuracy of multi class prediction using word frequency\")\n",
    "print(f\"Logistic Regression accuracy: {logistic_multi_frequency_accuracy}\")\n",
    "print(f\"MLP Classifier accuracy: {mlp_multi_frequency_accuracy}\")\n",
    "print(f\"MLP Regressor accuracy: {mlpr_multi_frequency_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPdFxtvQ3Smk"
   },
   "source": [
    "As expected the results are largely similar to the previous results. The MLP Rregressor had the best accuracy, and the other two models had similar accuracies. Also as expected, the results were slightly worse. This is proof that using word occurence is more powerful than using word frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMXlogEn4AsD"
   },
   "source": [
    "The final models I am going to train using this reduction method are models that train using the binary (positive/negative) classes. Since word occurrence seems to be better than frequency, I am going to use the polarity values that are only based on word occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "g5J7dj0K4WSs"
   },
   "outputs": [],
   "source": [
    "# collect targets into single array - using binary values\n",
    "y_train_binary = [1 if train['output'] > 5 else 0 for train in train_data]\n",
    "y_test_binary = [1 if test['output'] > 5 else 0 for test in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEmTM3b84kr3",
    "outputId": "5aa2dd69-cd91-4bbf-dfac-8733640feef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of binary class prediction using word occurrence\n",
      "Logistic Regression accuracy: 0.8498\n",
      "MLP Classifier accuracy: 0.85048\n",
      "MLP Regressor accuracy: 0.5468018166918556\n"
     ]
    }
   ],
   "source": [
    "# create the models and test accuracy using occurence and binary outputs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "logistic_binary_occurrence = LogisticRegression()\n",
    "logistic_binary_occurrence.fit(X_train_occurrence_np, y_train_binary)\n",
    "logistic_binary_occurrence_accuracy = logistic_binary_occurrence.score(X_test_occurrence_np, y_test_binary)\n",
    "\n",
    "mlp_binary_occurrence = MLPClassifier()\n",
    "mlp_binary_occurrence.fit(X_train_occurrence_np, y_train_binary)\n",
    "mlp_binary_occurrence_accuracy = mlp_binary_occurrence.score(X_test_occurrence_np, y_test_binary)\n",
    "\n",
    "mlpr_binary_occurrence = MLPRegressor()\n",
    "mlpr_binary_occurrence.fit(X_train_occurrence_np, y_train_binary)\n",
    "mlpr_binary_occurrence_accuracy = mlpr_binary_occurrence.score(X_test_occurrence_np, y_test_binary)\n",
    "\n",
    "print(\"Accuracy of binary class prediction using word occurrence\")\n",
    "print(f\"Logistic Regression accuracy: {logistic_binary_occurrence_accuracy}\")\n",
    "print(f\"MLP Classifier accuracy: {mlp_binary_occurrence_accuracy}\")\n",
    "print(f\"MLP Regressor accuracy: {mlpr_binary_occurrence_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSSczj_R5wbu"
   },
   "source": [
    "Switching to a binary output dramtically improved the accuracy of the predictions. The Logistic Regression accuracy and MLP Classifier accuary are now both around 85%. Surprisingly, the MLP Regressor, which was the best predictor on mutliclass, is the worst predictor on binary class outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWbZV6jM6w3j"
   },
   "source": [
    "It is clear that the prediction of binary outputs is easier, and more successful. The combination binary outputs, and using word occurrence over frequency has lead to the best results so far. For the next part of my report I am going to use a \"Bag-of-words\" model to try to improve the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNDEBt54D6Rm"
   },
   "source": [
    "# Bag of Words Model\n",
    "For the next part of my project I intend to use a bag of words technique where the inputs are large feature vectors, and each dimension of the vector is a different word from the review dictionary. But first, it is important to realize that there are ~90,000 words, and 50,000 samples. If each sample has an input vector with 90,000 dimensions, this would mean there would be 50000 x 90000 = 4.5 billion numbers. Since each number is a double, this would end up being 36 billion bytes of data, or about 36 gigabytes - which is too much memory. To get around this bottleneck I instead used minibatch training. <br><br>\n",
    "\n",
    "Minibatch training is where you train on small batches of the total input. This way, you use less memory, and still are able to train the model on all of the data. I chose a minibatch size of 1000 inputs. This means that each iteration of the partial fitting, the model only sees 1000 inputs, but over the course of 25 iterations the model will see every training sample. I also rotated through the testing samples in the same manner.<br><br>\n",
    "\n",
    "I intend to train two different models. The first is a SGDClassifer, which when the argument loss='log' is given to the model, acts like logistic regression during partial fitting. The second is another MLPClassifer. This was the best performing model when using the reduction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tJyVudnpgxTN"
   },
   "outputs": [],
   "source": [
    "# define minibatch size and number of iterations\n",
    "minibatch_size = 1000\n",
    "total_size = np.ceil(len(train_data))\n",
    "iterations = int(total_size / minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "cDetHHGbeaJ6"
   },
   "outputs": [],
   "source": [
    "# create SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbmtanciJ5_l"
   },
   "source": [
    "When I create the input vectors I am just going to use word occurrence in the review, not word frequency. If the word appears in the review, the feature vector will have the polarity value in that dimension, if it doesn't then just a zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2zIEZZYInix",
    "outputId": "2b47fab9-b8c6-4a20-abb1-6bfc29ff3a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 2/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 3/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 4/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 5/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 6/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 7/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 8/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 9/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 10/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 11/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 12/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 13/25: training accuracy - 0.923, validation accuracy - 0.923\n",
      "Iteration 14/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 15/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 16/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 17/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 18/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 19/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 20/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 21/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 22/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 23/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 24/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 25/25: training accuracy - 1.0, validation accuracy - 1.0\n"
     ]
    }
   ],
   "source": [
    "# train over number of iterations\n",
    "for i in range(iterations): \n",
    "  X_train_minibatch = []\n",
    "\n",
    "  # grab training targets\n",
    "  y_train_minibatch = y_train_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  X_test_minibatch = []\n",
    "\n",
    "  # grab testing targets\n",
    "  y_test_minibatch = y_test_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  # generate feature vectors\n",
    "  for train, test in zip(train_data[i * minibatch_size:(i + 1) * minibatch_size], test_data[i * minibatch_size:(i + 1) * minibatch_size]):\n",
    "    train_inputs = train['input']\n",
    "    train_vector = []\n",
    "    test_inputs = train['input']\n",
    "    test_vector = []\n",
    "\n",
    "    # look at all words and check if they exist in review words\n",
    "    # if the word exists append the polarity value\n",
    "    # if not, append 0\n",
    "    for word in range(len(vocab_values)):\n",
    "      if word in train_inputs:\n",
    "        train_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        train_vector.append(0)\n",
    "      \n",
    "      if word in test_inputs:\n",
    "        test_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        test_vector.append(0)\n",
    "\n",
    "    # add vectors to the minibatch\n",
    "    X_train_minibatch.append(train_vector)\n",
    "    X_test_minibatch.append(test_vector)\n",
    "\n",
    "  # test the fit after minibatches are created\n",
    "  clf.partial_fit(X_train_minibatch, y_train_minibatch, [0, 1])\n",
    "  validation_accuracy = clf.score(X_test_minibatch, y_test_minibatch)\n",
    "  training_accuracy = clf.score(X_train_minibatch, y_train_minibatch)\n",
    "  print(f\"Iteration {i + 1}/{iterations}: training accuracy - {training_accuracy}, validation accuracy - {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BtkPCTocH8Nl"
   },
   "outputs": [],
   "source": [
    "# create MLPClassifier - using 1000 neurons in hidden layer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BauJy4eW73VK",
    "outputId": "eab2cdab-93ea-4771-9594-bf1bf158b002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 2/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 3/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 4/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 5/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 6/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 7/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 8/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 9/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 10/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 11/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 12/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 13/25: training accuracy - 0.5, validation accuracy - 0.5\n",
      "Iteration 14/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 15/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 16/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 17/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 18/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 19/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 20/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 21/25: training accuracy - 0.0, validation accuracy - 0.0\n",
      "Iteration 22/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 23/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 24/25: training accuracy - 1.0, validation accuracy - 1.0\n",
      "Iteration 25/25: training accuracy - 1.0, validation accuracy - 1.0\n"
     ]
    }
   ],
   "source": [
    "# do same thing for mlp classifier\n",
    "\n",
    "for i in range(iterations):\n",
    "  X_train_minibatch = []\n",
    "  y_train_minibatch = y_train_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  X_test_minibatch = []\n",
    "  y_test_minibatch = y_test_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "  \n",
    "  for train, test in zip(train_data[i * minibatch_size:(i + 1) * minibatch_size], test_data[i * minibatch_size:(i + 1) * minibatch_size]):\n",
    "    train_inputs = train['input']\n",
    "    train_vector = []\n",
    "    test_inputs = train['input']\n",
    "    test_vector = []\n",
    "\n",
    "    for word in range(len(vocab_values)):\n",
    "      if word in train_inputs:\n",
    "        train_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        train_vector.append(0)\n",
    "      \n",
    "      if word in test_inputs:\n",
    "        test_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        test_vector.append(0)\n",
    "\n",
    "    X_train_minibatch.append(train_vector)\n",
    "    X_test_minibatch.append(test_vector)\n",
    "\n",
    "  mlp._partial_fit(X_train_minibatch, y_train_minibatch, [0, 1])\n",
    "  validation_accuracy = mlp.score(X_test_minibatch, y_test_minibatch)\n",
    "  training_accuracy = mlp.score(X_train_minibatch, y_train_minibatch)\n",
    "  print(f\"Iteration {i + 1}/{iterations}: training accuracy - {training_accuracy}, validation accuracy - {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRtQq7_xSvev"
   },
   "source": [
    "When you look at the results of this training, there is an obvious reaction, and a not so obvious reason. The obvious thing you see is that the validation accuracy is 100%. There is one reason this accuracy is so high, and its not because the model is perfect. It is because of the way the training samples were created: every postive sample come before every negative sample. The model is recognizing this and, weighting the appropriate output so heavily, that it always has the same output. This is clearly not correct, so I am going to shuffle the inputs and see if the model can learn this way instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xDBNtHZtDZ3o"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "train_data_shuffled = sklearn.utils.shuffle(train_data)\n",
    "test_data_shuffled = sklearn.utils.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nEuPVIrqVYGI"
   },
   "outputs": [],
   "source": [
    "# collect shuffled targets\n",
    "y_train_shuffled_binary = [1 if train['output'] > 5 else 0 for train in train_data_shuffled]\n",
    "y_test_shuffled_binary = [1 if test['output'] > 5 else 0 for test in test_data_shuffled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFyL8jSHYUXz",
    "outputId": "863b22dd-4a5f-4962-ac6a-93d3decfd29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/25: training accuracy - 0.945, validation accuracy - 0.49\n",
      "Iteration 2/25: training accuracy - 0.876, validation accuracy - 0.514\n",
      "Iteration 3/25: training accuracy - 0.948, validation accuracy - 0.492\n",
      "Iteration 4/25: training accuracy - 0.951, validation accuracy - 0.492\n",
      "Iteration 5/25: training accuracy - 0.964, validation accuracy - 0.515\n",
      "Iteration 6/25: training accuracy - 0.947, validation accuracy - 0.478\n",
      "Iteration 7/25: training accuracy - 0.954, validation accuracy - 0.529\n",
      "Iteration 8/25: training accuracy - 0.958, validation accuracy - 0.498\n",
      "Iteration 9/25: training accuracy - 0.941, validation accuracy - 0.498\n",
      "Iteration 10/25: training accuracy - 0.935, validation accuracy - 0.516\n",
      "Iteration 11/25: training accuracy - 0.96, validation accuracy - 0.509\n",
      "Iteration 12/25: training accuracy - 0.923, validation accuracy - 0.478\n",
      "Iteration 13/25: training accuracy - 0.945, validation accuracy - 0.508\n",
      "Iteration 14/25: training accuracy - 0.946, validation accuracy - 0.479\n",
      "Iteration 15/25: training accuracy - 0.945, validation accuracy - 0.466\n",
      "Iteration 16/25: training accuracy - 0.944, validation accuracy - 0.475\n",
      "Iteration 17/25: training accuracy - 0.901, validation accuracy - 0.542\n",
      "Iteration 18/25: training accuracy - 0.966, validation accuracy - 0.508\n",
      "Iteration 19/25: training accuracy - 0.965, validation accuracy - 0.506\n",
      "Iteration 20/25: training accuracy - 0.961, validation accuracy - 0.525\n",
      "Iteration 21/25: training accuracy - 0.956, validation accuracy - 0.47\n",
      "Iteration 22/25: training accuracy - 0.967, validation accuracy - 0.481\n",
      "Iteration 23/25: training accuracy - 0.977, validation accuracy - 0.519\n",
      "Iteration 24/25: training accuracy - 0.964, validation accuracy - 0.5\n",
      "Iteration 25/25: training accuracy - 0.966, validation accuracy - 0.489\n"
     ]
    }
   ],
   "source": [
    "# logistic regression learning with shuffled inputs\n",
    "clf_shuffled = SGDClassifier(loss='log')\n",
    "\n",
    "for i in range(iterations): \n",
    "  X_train_minibatch = []\n",
    "  y_train_minibatch = y_train_shuffled_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  X_test_minibatch = []\n",
    "  y_test_minibatch = y_test_shuffled_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  for train, test in zip(train_data_shuffled[i * minibatch_size:(i + 1) * minibatch_size], test_data_shuffled[i * minibatch_size:(i + 1) * minibatch_size]):\n",
    "    train_inputs = train['input']\n",
    "    train_vector = []\n",
    "    test_inputs = train['input']\n",
    "    test_vector = []\n",
    "\n",
    "    for word in range(len(vocab_values)):\n",
    "      if word in train_inputs:\n",
    "        train_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        train_vector.append(0)\n",
    "      \n",
    "      if word in test_inputs:\n",
    "        test_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        test_vector.append(0)\n",
    "\n",
    "    # add vectors to the minibatch\n",
    "    X_train_minibatch.append(train_vector)\n",
    "    X_test_minibatch.append(test_vector)\n",
    "\n",
    "  # test the fit after minibatches are created\n",
    "  clf_shuffled.partial_fit(X_train_minibatch, y_train_minibatch, [0, 1])\n",
    "  validation_accuracy = clf_shuffled.score(X_test_minibatch, y_test_minibatch)\n",
    "  training_accuracy = clf_shuffled.score(X_train_minibatch, y_train_minibatch)\n",
    "  print(f\"Iteration {i + 1}/{iterations}: training accuracy - {training_accuracy}, validation accuracy - {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNvTfpOnVX_7",
    "outputId": "71aeca57-703b-4284-e66b-a2a39a42c15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/25: training accuracy - 0.965, validation accuracy - 0.505\n",
      "Iteration 2/25: training accuracy - 0.947, validation accuracy - 0.508\n",
      "Iteration 3/25: training accuracy - 0.936, validation accuracy - 0.521\n",
      "Iteration 4/25: training accuracy - 0.934, validation accuracy - 0.502\n",
      "Iteration 5/25: training accuracy - 0.934, validation accuracy - 0.51\n",
      "Iteration 6/25: training accuracy - 0.932, validation accuracy - 0.521\n",
      "Iteration 7/25: training accuracy - 0.926, validation accuracy - 0.482\n",
      "Iteration 8/25: training accuracy - 0.943, validation accuracy - 0.506\n",
      "Iteration 9/25: training accuracy - 0.943, validation accuracy - 0.492\n",
      "Iteration 10/25: training accuracy - 0.942, validation accuracy - 0.515\n",
      "Iteration 11/25: training accuracy - 0.938, validation accuracy - 0.498\n",
      "Iteration 12/25: training accuracy - 0.952, validation accuracy - 0.502\n",
      "Iteration 13/25: training accuracy - 0.945, validation accuracy - 0.497\n",
      "Iteration 14/25: training accuracy - 0.943, validation accuracy - 0.506\n",
      "Iteration 15/25: training accuracy - 0.933, validation accuracy - 0.491\n",
      "Iteration 16/25: training accuracy - 0.934, validation accuracy - 0.512\n",
      "Iteration 17/25: training accuracy - 0.933, validation accuracy - 0.502\n",
      "Iteration 18/25: training accuracy - 0.943, validation accuracy - 0.52\n",
      "Iteration 19/25: training accuracy - 0.93, validation accuracy - 0.49\n",
      "Iteration 20/25: training accuracy - 0.937, validation accuracy - 0.515\n",
      "Iteration 21/25: training accuracy - 0.925, validation accuracy - 0.518\n",
      "Iteration 22/25: training accuracy - 0.939, validation accuracy - 0.506\n",
      "Iteration 23/25: training accuracy - 0.933, validation accuracy - 0.522\n",
      "Iteration 24/25: training accuracy - 0.928, validation accuracy - 0.516\n",
      "Iteration 25/25: training accuracy - 0.934, validation accuracy - 0.506\n"
     ]
    }
   ],
   "source": [
    "# mlp learning with shuffled inputs\n",
    "mlp_shuffled = MLPClassifier(1000)\n",
    "\n",
    "for i in range(iterations):\n",
    "  X_train_minibatch = []\n",
    "  y_train_minibatch = y_train_shuffled_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "\n",
    "  X_test_minibatch = []\n",
    "  y_test_minibatch = y_test_shuffled_binary[i * minibatch_size:(i + 1) * minibatch_size]\n",
    "  \n",
    "  for train, test in zip(train_data_shuffled[i * minibatch_size:(i + 1) * minibatch_size], test_data_shuffled[i * minibatch_size:(i + 1) * minibatch_size]):\n",
    "    train_inputs = train['input']\n",
    "    train_vector = []\n",
    "    test_inputs = train['input']\n",
    "    test_vector = []\n",
    "\n",
    "    for word in range(len(vocab_values)):\n",
    "      if word in train_inputs:\n",
    "        train_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        train_vector.append(0)\n",
    "      \n",
    "      if word in test_inputs:\n",
    "        test_vector.append(vocab_values[word])\n",
    "      else:\n",
    "        test_vector.append(0)\n",
    "\n",
    "    X_train_minibatch.append(train_vector)\n",
    "    X_test_minibatch.append(test_vector)\n",
    "\n",
    "  mlp_shuffled._partial_fit(X_train_minibatch, y_train_minibatch, [0, 1])\n",
    "  validation_accuracy = mlp_shuffled.score(X_test_minibatch, y_test_minibatch)\n",
    "  training_accuracy = mlp_shuffled.score(X_train_minibatch, y_train_minibatch)\n",
    "  print(f\"Iteration {i + 1}/{iterations}: training accuracy - {training_accuracy}, validation accuracy - {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFIXBy2vZFuI"
   },
   "source": [
    "After shuffling the inputs, the accuarcy hovered around 50%, not much better than random guess, so this method didn't work all too well. There is potential that more training could improve this method, but each of these training cycles took about 25-30 minutes, so it would have to potentially run for weeks to train enough to achieve a higher accuracy.<br><br>\n",
    "\n",
    "The last thing I am going to try in this project is do bag-of-words, but only on a certain number of the most common words, instead of the entire vocabuarly dictionary. <br><br>\n",
    "\n",
    "The first step to do this will be to rank each word by totaling the number of times that word appeared in the reviews. Again, I am only going to look at word occurrence in each review, not the total number of times a word was used. For words like \"and\" and \"the\" and \"but\" this will reduce their total popularity. <br><br>\n",
    "\n",
    "Since only the training inputs are used to fit the model, I am only going to look at the words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M79mObDXahXm"
   },
   "outputs": [],
   "source": [
    "def get_n_popular_words(n):\n",
    "  words = {}\n",
    "  for word in range(len(vocab_values)):\n",
    "    words[word] = 0\n",
    "\n",
    "  # count the number of word occurences\n",
    "  for train in train_data:\n",
    "    inputs = train['input']\n",
    "    for word in inputs:\n",
    "      words[word] += 1\n",
    "\n",
    "  sorted_words = sorted(words.items(), key=lambda item: item[1])\n",
    "  n_sorted_words = sorted_words[-n:]\n",
    "  most_popular = [p[0] for p in n_sorted_words]\n",
    "  return most_popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhhwXDa_fG8D"
   },
   "source": [
    "Now I can use feature vectors of any size, and hopefully fun the code faster to train more models. I am going to begin with the 1000 most popular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mpRvxR_xgIui"
   },
   "outputs": [],
   "source": [
    "def create_vector(input, most_popular):\n",
    "  vector = []\n",
    "  for word in most_popular:\n",
    "    if word in input:\n",
    "      vector.append(vocab_values[word])\n",
    "    else:\n",
    "      vector.append(0)\n",
    "  return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9xXYcHifFyO",
    "outputId": "4e2dde5c-8218-40f0-d549-f6b200214281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1000 most popular words\n",
      "Logistic Regression accuracy - 0.85864\n",
      "MLPClassifier accuracy - 0.85568\n"
     ]
    }
   ],
   "source": [
    "# logistic regression and mlp learning with 1000 most popular words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n = 1000 # number of popular words\n",
    "\n",
    "# creating mlp\n",
    "mlp_1000_most_popular = MLPClassifier(1000)\n",
    "\n",
    "#creating logistic regression\n",
    "lr_1000_most_popular = LogisticRegression(max_iter=200)\n",
    "\n",
    "X_train_1000 = []\n",
    "X_test_1000 = []\n",
    "\n",
    "most_popular_1000 = get_n_popular_words(n) # get most popular words\n",
    "\n",
    "# generate vectors\n",
    "for train, test in zip(train_data, test_data):\n",
    "  X_train_1000.append(create_vector(train['input'], most_popular_1000))\n",
    "  X_test_1000.append(create_vector(test['input'], most_popular_1000))\n",
    "\n",
    "lr_1000_most_popular.fit(X_train_1000, y_train_binary)\n",
    "lr_most_popular_1000_accuracy = lr_1000_most_popular.score(X_test_1000, y_test_binary)\n",
    "\n",
    "# training mlp\n",
    "mlp_1000_most_popular.fit(X_train_1000, y_train_binary)\n",
    "mlp_most_popular_1000_accuracy = mlp_1000_most_popular.score(X_test_1000, y_test_binary)\n",
    "\n",
    "print(\"Using 1000 most popular words\")\n",
    "print(f\"Logistic Regression accuracy - {lr_most_popular_1000_accuracy}\")\n",
    "print(f\"MLPClassifier accuracy - {mlp_most_popular_1000_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3djhF4tkqb1"
   },
   "source": [
    "Switching to the n most popular words is an extremely sizable improvement. Using just the first 1000 most popular words, the accuarcy of both Logistic Regression and the MLP Classifier are around 85%. This is much better, and these models are much more accurate than the previous bag-of-words models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XyQtgK4leCO"
   },
   "source": [
    "The final models I am going to train are the same model types (Logistic Regression, MLPClassifier), and this time use the 5000 most popular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHlM3WclkpQp",
    "outputId": "b50923e0-2cc7-49f7-8df9-ec5e7b38ba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5000 most popular words\n",
      "Logistic Regression accuracy - 0.87464\n",
      "MLPClassifier accuracy - 0.87412\n"
     ]
    }
   ],
   "source": [
    "# logistic regression and mlp learning with 5000 most popular words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "n = 5000 # number of popular words\n",
    "\n",
    "# creating mlp\n",
    "mlp_5000_most_popular = MLPClassifier(1000)\n",
    "\n",
    "#creating logistic regression\n",
    "lr_5000_most_popular = LogisticRegression(max_iter=200)\n",
    "\n",
    "X_train_5000 = []\n",
    "X_test_5000 = []\n",
    "\n",
    "most_popular_5000 = get_n_popular_words(n) # get most popular words\n",
    "\n",
    "# generate vectors\n",
    "for train, test in zip(train_data, test_data):\n",
    "  X_train_5000.append(create_vector(train['input'], most_popular_5000))\n",
    "  X_test_5000.append(create_vector(test['input'], most_popular_5000))\n",
    "\n",
    "lr_5000_most_popular.fit(X_train_5000, y_train_binary)\n",
    "lr_most_popular_5000_accuracy = lr_5000_most_popular.score(X_test_5000, y_test_binary)\n",
    "\n",
    "# training mlp\n",
    "mlp_5000_most_popular.fit(X_train_5000, y_train_binary)\n",
    "mlp_most_popular_5000_accuracy = mlp_5000_most_popular.score(X_test_5000, y_test_binary)\n",
    "\n",
    "print(\"Using 5000 most popular words\")\n",
    "print(f\"Logistic Regression accuracy - {lr_most_popular_5000_accuracy}\")\n",
    "print(f\"MLPClassifier accuracy - {mlp_most_popular_5000_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr6qhggamNQf"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In conclusion, I think that the models I trained were successful. The initial bag of words models trained in minibatch iterations were too large to train in any reasonable time, but the performance could improve given much more training. The models that simply reduced the vectors down were also very successful. These showed that word occurrence is better than word frequency which is what I used in the rest of my project. These models also showed that predicting overall sentiment - positive or negative - is significantly easier than the number of stars. Different people have different criterion they use for their individual ratings, and it is more important to look at if the review was positive or negative, rather than the number of stars. The final models I trained, the ones that used sparse vectors of only the n most common words were also very successful. I think with more time I could fine tune the hyper-parameters of these models and achieve even better results.<br><br>\n",
    "\n",
    "I am impressed by how well these models performed, and I think they could all keep heading this direction to perform better and better after more training and time. The accuracy of the models increased from 1000 most popular to 5000 most popular. This increase shows that using more words improves the model's accuracy. The MLP model took far longer than the logistic regression model, while achieving the same accuracies. In the future, the MLP could be optimized, or logisitic regression could be used only. <br><br>\n",
    "\n",
    "Overall, I think that these models were successful at performing sentiment analysis on the IMDb dataset, and there are many optimizations that could improve this further."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "B455Project4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
